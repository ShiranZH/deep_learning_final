{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1574382-ae81-43f8-ab77-d2892a59d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils.utils import cutmix, cutmix_criterion\n",
    "from utils.config import config\n",
    "from model import MobileFormer\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476dea25-83fd-41a6-8b8c-5b299a2d0ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model mf52\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# create model\n",
    "# assert args.name in ['mf52', 'mf294', 'mf508'] \n",
    "model_name = 'mf52'\n",
    "\n",
    "print('create model {}'.format(model_name))\n",
    "cfg = config[model_name]\n",
    "model = MobileFormer(cfg)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a4f8db-ab93-4164-ab57-dc3d5b6ea520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./checkpoint/model_best.pth.tar',map_location=device)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_acc1 = checkpoint['best_acc1']\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f823d2-8b64-4f0f-a10c-8ac497718308",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'\n",
    "traindir = os.path.join(path, 'train')\n",
    "testdir = os.path.join(path, 'test')\n",
    "\n",
    "cinic_mean = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std = [0.24205776, 0.23828046, 0.25874835]\n",
    "\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = cinic_mean,std = cinic_std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = cinic_mean,std = cinic_std),\n",
    "])\n",
    "\n",
    "trainset = datasets.ImageFolder(traindir, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = datasets.ImageFolder(testdir, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=200, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757dc47-54db-47d8-9e57-1cba8d982da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trainset lens: ', trainset.__len__())\n",
    "print('testset lens: ', testset.__len__())\n",
    "\n",
    "# print the label\n",
    "classes  = trainset.classes\n",
    "class_to_idx = trainset.class_to_idx\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0075a-5d9f-4b81-9f9f-a5cfe4018bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels, classes,name):\n",
    "    \n",
    "    fig = plt.figure(figsize = (10, 10));\n",
    "    ax = fig.add_subplot(1, 1, 1);\n",
    "    cm = confusion_matrix(labels, pred_labels);\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
    "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "    plt.xticks(rotation = 20)\n",
    "    plt.savefig(\"./checkpoint/\" + name)\n",
    "    \n",
    "def eval_peformance(model,name):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    labels = []\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        #end = time.time()\n",
    "        for i, (images, target) in enumerate(test_loader):\n",
    "            \n",
    "            \n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss+=loss.item()\n",
    "            \n",
    "            \n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            \n",
    "            labels.append(target)\n",
    "            probs.append(pred)\n",
    "            \n",
    "        \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_acc = correct / float(len(test_loader.dataset))\n",
    "        \n",
    "\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100. * test_acc))\n",
    "    \n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "    \n",
    "    plot_confusion_matrix(labels.cpu(), probs.cpu(), classes,name) \n",
    "\n",
    "\n",
    "    \n",
    "def get_data_from_txt(path):\n",
    "    list = []\n",
    "    with open(path,'r') as f:\n",
    "        for line in f:\n",
    "            list.append(line.strip('\\n')) \n",
    "    return list\n",
    "\n",
    "def plot_record_data(train_list,test_list,label):\n",
    "    plt.figure()\n",
    "    ax=plt.axes()\n",
    "    plt.xlabel('Round')  \n",
    "    plt.ylabel(label)   \n",
    "\n",
    "    plt.plot(range(len(train_list)), train_list, label=\"train \"+ label)\n",
    "    plt.plot(range(len(test_list)), test_list, label=\"test \"+label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(label+\" curve\")\n",
    "    plt.savefig(\"./checkpoint/\"+label+\"_curve.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af12474-08d3-45fb-8706-8e01ba857251",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_path=\"./exp_record\"\n",
    "train_loss_txt = os.path.join(record_path,\"train_loss.txt\")\n",
    "train_acc_txt = os.path.join(record_path,\"train_acc.txt\")\n",
    "test_loss_txt = os.path.join(record_path,\"test_loss.txt\")\n",
    "test_acc_txt = os.path.join(record_path,\"test_acc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81663967-0d65-4796-86fc-fcc6320a7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list=get_data_from_txt(train_loss_txt)\n",
    "train_acc_list=get_data_from_txt(train_acc_txt)\n",
    "test_loss_list=get_data_from_txt(test_loss_txt)\n",
    "test_acc_list=get_data_from_txt(test_acc_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4835047-5aef-446c-b043-9b77323392b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_record_data(train_loss_list,test_loss_list,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b874d-c97f-4157-9807-5884155bda0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_record_data(train_acc_list,test_acc_list,'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0663a6a-7910-45d0-90d1-45a045aebcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_peformance(model,\"confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
